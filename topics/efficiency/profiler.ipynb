{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027cd52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.profilers import PyTorchProfiler\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.profiler import schedule\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287f1030",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10(\n",
    "    root=\"../../assets/cifar10\", \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transforms\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844ac6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, model, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"val_acc\", acc)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a603d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"./profiler_logs\"\n",
    "\n",
    "profiler = PyTorchProfiler(\n",
    "    dirpath=log_dir,\n",
    "    filename=\"profile_report\",\n",
    "    schedule=schedule(\n",
    "        wait=2,     # skip first steps (startup noise)\n",
    "        warmup=2,   # warm-up steps\n",
    "        active=6,   # recorded steps\n",
    "        repeat=1\n",
    "    ),\n",
    "    profile_memory=True,\n",
    "    record_shapes=True\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_steps=14,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    profiler=profiler,\n",
    "    logger=False,\n",
    "    enable_checkpointing=False,\n",
    "    enable_model_summary=False,\n",
    "    enable_progress_bar=False\n",
    ")\n",
    "\n",
    "model = \n",
    "lit_model = LitModel(lr=1e-3)\n",
    "trainer.fit(lit_model, train_loader)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
